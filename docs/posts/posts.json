[
  {
    "path": "posts/2021-02-20-california-oil-spills/",
    "title": "California Oil Spills",
    "description": "Choropleth Map Using `ggplot2`",
    "author": [
      {
        "name": "Kathleen Cotti",
        "url": {}
      }
    ],
    "date": "2021-02-20",
    "categories": [],
    "contents": "\nSummary:\nThis post explores how to build a static choropleth map with R and the ggplot2 package. It shows how to load spatial data into R, merge region features between datasets, and build a finalized map of 2008 counts of inland oil spills in California counties as a fill color gradient.\nI first had issues plotting the oil spills as fill color on the map when I used two separate geom_sf() layers, but I realized I could merge the data frame and then use the number column aesthetically as the fill color of the map. In doing this project, I became more familiar with reading in and wrangling spatial data, using the sf package functions, and how to use the viridis package for color gradients. I also used the guide function to update my legend.\nFinding & Downloading Spatial Data:\nA choropleth map requires a geospatial dataset to provide the region boundaries, in this example we are looking at California counties. First, I had to find & download a shapefile data for borders of California counties.\nYou also need another geospatial dataset with numeric variables for each location that will we use to color the counties. I used download data from CA DFW Oil Spill Incident Tracking URL\nFirst, I loaded the spatial data sets into R using the read_sf() funtion from the sf package. I created a folder in my project root named “data” to store all data files & then the oil spatial data files are in a folder labeled “Oil_Spill_Tracking” and the California counties boundary data in a folder labeled “ca_counties”. I then use the here() function from the janitor package to give a clear file path to the shape files.\n\n\nhide\n\n# Read in the oil spatial data: \noil_spill_data <- read_sf(here(\"data\",\"Oil_Spill_Tracking\",\"Oil_Spill_Incident_Tracking_%5Bds394%5D.shp\")) %>% \n  clean_names()\n\n# Read in the CA counties data as an entire layer:\nca_counties <- read_sf(here(\"data\",\"ca_counties\"), layer = \"CA_Counties_TIGER2016\") %>% \n  clean_names() %>% \n  select(name) \n\n\n\nNext, I checked the projections, or how the coordinate reference systems are displayed, of the spatial data sets using the st_crs() function from the sf package. When merging two data sets to make this map, it is important that the projections of both data sets match or you’ll encounter difficulties in analysis & mapping. If the datasets have different projections, the st_transform() function can be used to transform one spatial data set to match the other, as shown below:\n\n\nhide\n\n#Check the Projections:\n# st_crs(oil_spill_data) \n# WGS 84\n\n# st_crs(ca_counties)\n# WGS 84\n\n#Set this data set to have the same CRS as above:\nca_counties <- st_transform(ca_counties, st_crs(oil_spill_data))\n\n\n\nData Wrangling of Oil Data:\nFor this analysis, I specifically plotted the number of inland oil spills per California county in 2008. Therefore, some data wrangling using functions from the dplyr package was necessary to get counts per county:\n\n\nhide\n\n# Data Wrangling - count oil spills for ca county:\n## Make a subset of data:\ninland_subset <- oil_spill_data %>% \n# Rename county for simplificaiton:\n  rename(county = localecoun) %>% \n# Only keep obervations from inland areas:\n  filter(inlandmari == \"Inland\") %>% \n# Group oil spills by county:\n  group_by(county) %>% \n# Count the number of inland oil spills per county:\n  count(inlandmari) %>% \n# Remove the inland column for simplification:\n  select(-inlandmari)\n\n\n\nMerge the spatial data sets:\nIn order to plot the oil data with the California counties outlines, I merged the data so I could plot the number of oil spills as a fill color gradient in the map\n\n\nhide\n\n# Join the data sets into a single data frame:\ncounties_oil <- st_join(ca_counties, inland_subset) \n\n\n\nMake a customized chloropleth map with ggplot2:\n\n\nhide\n\n#Make a Static Chloroleth Map:\nggplot() +\n  geom_sf(data = counties_oil,\n          aes(fill = n),\n          size = 0,\n          color = \"white\") +\n  scale_fill_viridis(option = \"inferno\", \n                     breaks = c(50, 100, 150, 200, 250, 300, 350, 400),\n                     begin = 0.1, \n                     end = 0.9,\n                     guide = guide_legend(keyheight = unit(5, units = \"mm\"), keywidth=unit(5, units = \"mm\"))) +\n  theme_void() +\n  labs(title = \"2008 Inland Oil Spill Events Across All California Counties\",\n       fill = \"Number of Oil Spills\") +\n  theme(\n    plot.background = element_rect(fill = \"#f5f5f3\", color = NA),\n    plot.title = element_text(size = 14)\n  )\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-20-california-oil-spills/california-oil-spills_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2021-02-20T16:27:05-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-20-harry-potter-text-analysis/",
    "title": "Harry Potter & The Sorcerer's Stone",
    "description": "Text Data Wrangling, Word Cloud Using `ggplot` & Sentiment Analysis",
    "author": [
      {
        "name": "Kathleen Cotti",
        "url": {}
      }
    ],
    "date": "2021-02-20",
    "categories": [],
    "contents": "\nSummary:\nThis post explores how to build a word cloud using ggplot & conduct sentiment analysis using the NRC lexicon. It shows how to load in pdf text data in R, get text data in tidy & tokenized format, and make finalized data visualizations for word frequencies & sentiment in Harry Potter & The Sorcerer’s Stone.\nThis was my first attempt at text analysis, and I had so much fun wrangling one of my favorite books into cool data visualizations. I became more familiar with using the stringr functions, and how to read in and tidy text. I ran into issues with my sentiment analysis plot since the chapter numbers were written out in words instead of as numbers, but I used mutate(case_when = ) to change them to numbers. I also practiced using scales = FREE to tidy up by sentiment data visualization. I also strengthened my skills in ggplot using then theme function to update the axis text size, and played around with background color in my first data visualization.\nReading in PDF Text Files:\n\n\nhide\n\nharry_potter_text <- pdf_text(here(\"data\", \"harry_potter.pdf\"))\n\n\n\nTidying up the Text Data:\nFirst, the text data must be transformed into a data frame using the data.frame function. This will make each page of the book into a separate row in the new data set. Then I did the following steps to tidy the text data frame: - Removed the pages before Chapter 1 starts using the slice() function - Removed excess white space using str_squish - Made a new column for chapter & populated when the row has “CHAPTER” in it & populated with NA for the other rows. Then used fill() to populate with the chapter number & used separate to separate into the word chapter and the number.\n\n\nhide\n\n# Make a tidy data subset:\nharry_potter_tidy <- data.frame(harry_potter_text) %>% \n# Remove the lines in the data frame before Chapter 1: \n  slice(-(1:6)) %>% \n# Remove excess white spaces: \n  mutate(harry_potter_text = str_squish(harry_potter_text)) %>% \n# Make a new column for chapter - if there is \"CHAPTER\" in the text column it will add \"CHAPTER\" to the chapter column and if not it will populate with NA:\n  mutate(chapter = case_when(\n    str_detect(harry_potter_text, pattern = \"CHAPTER\") ~ harry_potter_text,\n    TRUE ~ NA_character_\n  )) %>% \n# Populate the NA values in the chapter column with the chapter number until the next non-NA value:\n  fill(chapter) %>% \n# Separate the chapter column into the word chapter and the number: \n  separate(col = chapter, into = c(\"ch\", \"number\"), sep = \" \") %>% \n# Make numbers to lowercase numbers: \n  mutate(number = str_to_lower(number)) %>% \n# Remove un-necessary chapter column: \n  select(number, harry_potter_text) \n\n\n\nGet the Data into Tokenized Text Format:\nThen I use the unnest_tokens function to make each word in the book into a separate row, and then used anti_join() function to remove stop words:\n\n\nhide\n\n# Get this into tokenized text format:\nharry_potter_tokens <- harry_potter_tidy %>% \n  unnest_tokens(word, harry_potter_text) \n\n# Remove Stop Words:\nharry_nostop <- harry_potter_tokens %>% \n  anti_join(stop_words) \n\n\n\nData Wrangling for Word Frequency Word Cloud:\nI chose to make a word cloud of Chapter 15, “The Forbidden Forest”, using the 100 most used words in the chapter, so I needed to wrangle the data to get the frequencies of words in the chapter:\n\n\nhide\n\n#Count words by chapter:\nharry_counts <- harry_nostop %>% \n  count(number, word) \n\n#Find top 100 words in chapter 15:\nharry_ch15_top_100 <- harry_counts %>% \n# Only keep words from chapter 15:\n  filter(number == \"fifteen\") %>% \n# Arrange in decending order: \n  arrange(-n) %>% \n# Only keep top 100: \n  slice(1:100)\n\n\n\nMake a Word Cloud Using ggplot:\n\n\nhide\n\nggplot(data = harry_ch15_top_100, aes(label = word)) +\n  geom_text_wordcloud(aes(color = n, size = n)) +\n  scale_size_area(max_size = 12) +\n  theme_minimal() +\n  scale_color_viridis(option = \"magma\",\n                      begin = .4,\n                      end = 1) +\n  theme(plot.background = element_rect(fill = \"gray18\",color = NA)) +\n  labs(title = \"100 Most Used Words in Harry Potter & The Sorcerer's Stone \\n Chapter 15: The Forbidden Forest\") +\n  theme(plot.title = element_text(hjust = 0.5, size = 14, color = \"white\", face = \"bold\"))\n\n\n\n\nData Wrangling for Sentiment Analysis:\nI used the NRC lexicon for this sentiment analysis, which classifies words into ten emotional bins. First, I had to join the nrc lexicon with my tidy text data set using inner_join(). Then, I found counts of how many times the sentiment was reflected by words for each chapter. Since the chapter numbers were written out in words, I used the mutate() function to change the words to the number form\n\n\nhide\n\n#Inner join with NRC lexicon:\nharry_nrc <- harry_nostop %>% \n  inner_join(get_sentiments(\"nrc\")) \n\n# Count of times the 10 sentiments are reflected by words in each chapter:\nharry_nrc_counts <- harry_nrc %>% \n  mutate(number = case_when(number == \"one\" ~ \"1\",\n                            number == \"two\" ~ \"2\",\n                            number == \"three\" ~ \"3\",\n                            number == \"four\" ~ \"4\",\n                            number == \"five\" ~ \"5\",\n                            number == \"six\" ~ \"6\",\n                            number == \"seven\" ~ \"7\",\n                            number == \"eight\" ~ \"8\",\n                            number == \"nine\" ~ \"9\",\n                            number == \"ten\" ~ \"10\",\n                            number == \"eleven\" ~ \"11\",\n                            number == \"twelve\" ~ \"12\",\n                            number == \"thirteen\" ~ \"13\",\n                            number == \"fourteen\" ~ \"14\",\n                            number == \"fifteen\" ~ \"15\",\n                            number == \"sixteen\" ~ \"16\",\n                            number == \"seventeen\" ~ \"17\",\n                            )) %>% \n  count(sentiment, number) \n\n\n\nSentiment Analysis Data Visualization\nIn order to visualize the sentiment throughout the book, I plotted the sentiment counts per chapter using ggplot and I used facet_wrap() to separate the column graphs into individual graphs for each chapter.\n\n\nhide\n\n#Plot the counts of each of the 10 sentiments - see the emotion per chapter:\nggplot(data = harry_nrc_counts, aes(x = sentiment, y = n)) +\n  geom_col(aes(fill = number), show.legend = FALSE) +\n  theme_minimal() +\n  coord_flip() +\n  facet_wrap(~number, scales = \"free\") +\n  labs(title = \"Sentiment Analysis by Chapter of Harry Potter & \\n The Sorcerer's Stone\",\n       x = \" \", y = \" \") +\n  theme(plot.title = element_text(hjust = 0.5, size = 15, face = \"bold\")) +\n  theme(axis.text.x = element_text(size = 4, face = \"bold\")) +\n  theme(axis.text.y = element_text(size = 3.5, face = \"bold\")) +\n  theme(strip.text.x = element_text(size = 6, face = \"bold\"))\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-20-harry-potter-text-analysis/harry-potter-text-analysis_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2021-02-20T16:32:40-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-20-snowshoe-hares-in-bonanza-creek/",
    "title": "Snowshoe Hares in Bonanza Creek",
    "description": "Mini Report: Data Visualizations, T-Tests & Linear Regression Analysis",
    "author": [
      {
        "name": "Kathleen Cotti",
        "url": {}
      }
    ],
    "date": "2021-02-20",
    "categories": [],
    "contents": "\nSummary:\nThis post includes a mini-report I completed for my Environmental Data Science course in Fall of 2020 at the Bren School. I learned how to customize gg_beeswarm plots and descriptive statistic tables with kableExtra. I also practiced running two-sample t-tests and linear regression analysis in R and describe the outcomes in this report.\nA. Introduction:\nThis report provides an exploratory overview of snowshoe hare physical data collected in the Bonanza Creek Experimental Forest in the Alaskan Tanana Valley from 1998 - 2012. Snowshoe hares are a keystone prey species in this region and the study aimed to describe fluctuations in snowshoe hare population density (Kielland et al. 2017). Specifically, the counts of trapped juvenile snowshoe hares was explored across the course of the study, juvenile snowshoe hare weight was compared between male and females across the three sampling sites, and the relationship(s) between hind foot length and juvenile weight were explored in this report.\nB. Data & Analyses:\nSnowshoe hare weight and size measurements were collected from capture-recapture trapping and made available by Dr. Knut Kielland and colleagues at the Bonanza Creek LTER, a partnership between the University of Alaska Fairbanks and the US Forest Service and part of the US Long Term Ecological Research Network. The data contain observations for 3197 snowshoe hare trappings, collected over 14 years (1998-2012), in three sampling sites (bonrip or Bonanza Riparian, bonmat or Bonanza Mature, bonbs or Bonanza region with Mature Lowland Spruce). Changes in annual juvenile snowshoe trapping counts are displayed in a bar graph, and the distribution of juvenile snowshoes between sex and grid location is displayed using a beeswarm and boxplot. Following Exploratory Data Visualization, juvenile hare weights between male and female hares are compared by Welch’s two-sample t-tests using a significance level of 0.05 throughout. Differences between groups are described by Cohen’s d effect size. The relationship between hind foot length and weight is explored by a simple linear regression. Are analyses are in R version 4.0.2 using RStudio version 1.3.1056.\nC. Exploratory Findings:\ni) Annual Juvenile Hare Trap Counts and Descriptive Statistics:\n\n\nhide\n\n#Create a new subset of data converting the dates in date format & with a new column for year:\nbonanza_dates_converted <- bonanza_hares_data %>% \n  mutate(date_new = mdy(date)) %>%  \n  mutate(year = year(date_new))\n\n#Create a new subset filtering to keep only juvenile hares & group data by year and count:\njuvenile_hare <- bonanza_dates_converted %>%  \n  filter(age == \"j\")  %>% \n  count(age, year) \n\n#Create a bar graph of juvenile hare counts per year: \nggplot(data = juvenile_hare, aes(x = year, y = n)) +\n  geom_col(fill = \"darkseagreen4\") +\n  labs(x = \"Year\", y = \"Count\", title = \"Number of Juvenile Snowshoe Hares Trapped in Bonanza Creek \\n Experimental Forest between 1998 and 2012\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  scale_x_continuous(breaks = c(1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012))\n\n\n\n\nFigure 1: Figure 1: Bar graph displaying counts of juvenile snowshoe hares trapped per year of the study (1998-2012). Sex and grid (sampling site) were not considered as variables here. No data is available for hare age in 1998, 2002, and 2009 therefore counts of juveniles trapped can not be included for these years. Data: Kielland et al. (2017)\n\n\n\nhide\n\n#Generate summary statistics for the juvenile hare data:\njuvenile_summary <- juvenile_hare %>% \n  summarize(mean = mean(n), #Find the mean of the number of hares \n            median = median(n), #Find the median of the number of hares\n            max =max(n), #Gives max\n            min = min(n)) #Gives min\n\n#Save summary stats to be used in analysis:\nmean_hare <- juvenile_summary[1,1] #Stores mean as an object\nmedian_hares <- juvenile_summary[1,2] #Stores median as an object\nmax_hares <- juvenile_summary[1,3] #Stores max as an object\nmin_hares <- juvenile_summary[1,4] #Stores min as an object\n\n\n\nThe minimum juvenile snowshoe hare trapping count in this region is 2, and the maximum is 126. According to the data available for this report, this minimum occurred in 2010 and the maximum occurred in 1999. The mean number of juvenile snowshoes trapped per year is 31.5. Since the maximum in 1999 is a large outlier, the mean is a skewed measure of central tendency. The median number of juvenile snowshoes trapped annually is 18.5, and since this dataset is largely skewed by outliers this is a more accurate measure of central tendency. The general trend seen in the histogram is a decrease in the number of juvenile hares trapped from 1999 to 2012, with a large decrease between 1999 and 2001. Accounting for the number of traps placed per year and the time the traps were left out would help to standardize the juvenile count data further, since having a larger number of traps or traps being left out longer could correlate to increased numbers of trapped hares. It would be useful to have consistent data collection techniques, such as ages notated in each year. Since age data was not collected in 1998, 2002, and 2009 we can not see a trend across the entire data set for juvenile counts.\nii) Difference in Juvenile Hare Weight Between Male and Female across grid (sampling site) locations:\n\n\nhide\n\n#Create a new subset of data containing weight, sex and location variables of juveniles:\nj_hare_weight <-  bonanza_dates_converted %>% \n  filter(age == \"j\") %>%\n  mutate(Sex = case_when(sex == \"f\" ~ \"Female\",  #Rename variables for clarity in graphical representation\n                         sex == \"m\" ~ \"Male\")) %>% \n  mutate(Grid = case_when(grid == \"bonbs\" ~ \"Bonanza\", \n                          grid == \"bonmat\" ~ \"Bonanza Mature\", \n                          grid == \"bonrip\" ~ \"Bonanza Riparian\")) %>% \n  select(weight, Sex, Grid) \n\n#Generate summary statistics for the weight data grouped by sex and grid: \nj_hare_weight_summary <- j_hare_weight %>% \n  group_by(Sex, Grid) %>% \n  summarize(mean = mean(weight,na.rm=TRUE), \n            median = median(weight, na.rm=TRUE),\n            sd = sd(weight, na.rm=TRUE),\n            n = n()) \n\n#Create a beeswarm plot of weight distributed facet wrapped by grid with a boxplot on top displaying summary statistics: \nggplot(data = j_hare_weight, \n       aes(x = Sex, \n           y = weight)) +\n  geom_beeswarm(aes(color = Sex), alpha = 0.6) + \n  geom_boxplot(fill = NA, \n               width = 0.2, \n               outlier.color = NA) +\n  stat_summary(fun=mean, \n               geom=\"point\", \n               shape=20, \n               size=4, \n               color=\"black\", \n               fill=\"black\") +\n  scale_color_manual(values = c(\"darkseagreen4\",\"goldenrod2\"), \n                     na.value = \"gray10\") +\n  theme_grey() +\n  labs(x = \"Sex\",\n       y = \"Weight (g)\",\n       title = \"Weight of Male vs. Female Juvenille Snowshoe Hares in Each Grid\",\n       color = \"Sex\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  facet_wrap(~Grid)\n\n\n\n\nFigure 2: Figure 2: Weight (g) observations for male, female, and NA (Undetermined) juvenile snowshoe hares in each of the three grid locations (bonbs, bonmat, and bonrip). Dark Green(Female), Golden Yellow(Male), and Gray (NA) points indicate individual observations for weight (g) of juvenile snowshoe hares. Box endpoints indicate the 25th and 75th percentile values; the black line and black point within the box indicate the median and mean value for each gender in each grid, respectively. Data: Kielland et al. (2017)\n\n\n\nWeights were compared across all three grid sites and between sex of the juvenile snowshoe hare population. On average male hares in each grid location have larger mean and median body weights in each of the three grid zones than female hares and hares with undetermined sex. The average weights of both male and female hares was largest in the Bonanza grid than the other grid locations. All distributions appear relatively normally and symmetrically distributed. The Bonanza grid has a significant male outlier causing the mean and median to differ, as the mean is skewed negatively. The Bonanza grid female distribution tail shows slight negative skew but with no significant outliers and similar mean and median values. The Bonanza Mature grid distributions show no significant outliers, but the female distribution mean is skewed negatively. The Bonanza Riparian distribution of Females has a significant positive outlier, but the mean and median values are relatively similar. Overall, the data appears relatively normally distributed between sex and grid and we can continue with the data analysis.\niii.) Difference in Weight Between Male and Female Juvenile Snowshoe Hares:\nAs a starting point, the distribution of male and female juvenile hare weights were explored using both histograms and quantile-quantile plots. The distributions are relatively normal, and both our sample allowing us to move forward with our t-test.\nTable 1: Descriptive Statistics (Mean,Standard Deviation, and Sample Size) of Male and Female Juvenile Snowshoe Hares from all grids. Data: Kielland et al. (2017)\n\n\nhide\n\n#Create an organized Table in the Knitted Doc:\nkbl(j_gender_summary) %>% \n  kable_material(\"hover\", full_width = F)\n\n\n\nSex\n\n\nMean Weight (g)\n\n\nStandard Deviation Weight (g)\n\n\nSample Size\n\n\nFemale\n\n\n855.3909\n\n\n292.2526\n\n\n200\n\n\nMale\n\n\n945.8589\n\n\n333.2151\n\n\n163\n\n\nhide\n\n# Get the Means and Standard Deviations for each stored as objects:\nmean_f <- j_gender_summary[1,2] \nmean_m <- j_gender_summary[2,2]\nsd_f <- j_gender_summary[1,3]\nsd_m <- j_gender_summary[2,3]\n\n#Pull vectors for weight for male & female juvenile hares:\nj_female <- j_gender_comparison %>% \n  filter(Sex == \"Female\") %>% \n  filter(weight > 0) %>% \n  pull(weight)\n\nj_male<- j_gender_comparison %>% \n  filter(Sex == \"Male\") %>% \n  filter(weight > 0) %>% \n  pull(weight)\n\n#Run the T-test: \ngender_ttest <- t.test(j_female, j_male)\ngender_ttest_tidy <- tidy(gender_ttest)\n\n#Get the Effect Size:\ngender_effsize <- cohen.d(j_female, j_male)\n\n\n\nOn average, juvenile male snowshoe hairs have larger body weights than juvenile female snowshoes (945.86 \\(\\pm\\) 333.22 and 855.39 \\(\\pm\\) 292.25 mm, respectively; mean \\(\\pm\\) 1 standard deviation). While the absolute difference in means is 90.47 mm (a 10.05% difference). This difference in means is significant, as the p-value is below our established alpha value of 0.05 (Welch’s two-sample t-test: t(325.02) = -2.71, p < 0.001), meaning we would reject the null hypothesis and assume that the samples were drawn from populations with different means. The effect size is small (Cohen’s d = -0.29) meaning there is a difference in the means but it is difficult to notice.\niv) Relationship between juvenille weight & hind foot length:\nAs a starting point, the relationship between juvenile weight and hind foot length was explored across the sexes (ie. ignoring sex) as seen in Figure 3. Further analysis is needed to compare the relationship between juvenile weight and hind foot length within each sex, and should include sex as a variable.\n\n\nhide\n\n#Create a scatterplot to explore the relationship between variables: \nggplot(data = hare_foot, \n       aes(x = hindft,\n           y = weight)) +\n         geom_point(color = \"darkseagreen4\",\n                    show.legend = FALSE,\n                    size = 2.5,\n                    alpha = 0.7) +\n  labs(x = \"Hind Foot Length (mm)\",\n       y = \"Body Weight (g)\", \n       title = \"Relationship between Juvenile Hare Body Weight and Hind Foot Length\") +\n  theme_gray() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nFigure 3: Figure 3: Relationship between juvenile hare foot length (mm) and body weight (g).Points indicate individual snowshoe hare measurements.\n\n\n\n\n\nhide\n\n#Plot the Linear Regression: \nggplot(data = hare_foot, aes(x = hindft, y= weight)) +\n  geom_point(size = 1.5) +\n  geom_smooth(method = \"lm\",\n              color = \"darkseagreen4\",\n              size = 2,\n              fill = \"goldenrod2\",\n              alpha = 0.2) +\n  labs(x = \"Hind Foot Length (mm)\", y = \"Weight (g)\", title = \"Linear Regression Model Describing how Snowshoe Hare Weight \\n Changes with respect to Hind Foot Length\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  ggpubr::stat_regline_equation(label.x = 65, label.y = 1500) \n\n\n\n\nFigure 4: Relationship between hindfoot length (mm) and body weight (g) for all juvenile snowshoe hares. Points indicate individual hare measurements. Linear model summary: \\(\\beta\\)1 = 9.52 g mm-1, p < 0.001, R2 = 0.3, Pearson’s r = 0.55).\nThe slope of the regression equation is \\(\\beta\\) = 9.52, meaning for every one unit increase in hind foot length (mm) we expect an average increase in hare weight of \\(\\beta\\) = 9.52 grams. The R2 value is 0.3 meaning 30% of the variation in juvenile hare weight can be explained by the variation in hind foot length. The Pearson’s r is r = 0.55 which indicates there is a medium level of correlation between the variables. These results indicate there is positive correlation between the variables; however, since only 30% of the variation in weight can be explained by the hind foot length a multiple regression with more explanatory variables would be needed to explain the variation in juvenile hare weights, such as possibly accounting for the sex, age, or length of the hare.\nDiagnostic plots (not included) show that this model does not align with the assumptions for linear regression. The QQ plot is not linear throughout indicating the residuals are not normally distributed. The cooks distance test shows values outside the red dotted line indicating the possibility of outliers that can skew the model. The residuals appear heteroskedastic and the spread appears to be increasing across the model. There is an obvious pattern that the residuals are not normally distributed across the predicted trendline; therefore, linear regression was not the best model for this data and multiple regression should be considered.\nD. Summary:\nExploratory data analysis reveals the following initial findings:\nThe number of juvenile snowshoe hare trapping counts decreased over the course of the study (1998-2012).\nMale juvenile snowshoe hares have larger mean and median body weights than female juveniles (the difference is significant and the effect size is small).\nHind Foot Length is not perfectly linearly related with hare weight across all juvenile hares in the dataset; however, there is positive correlation between the variables (r* = 0.55) , and a portion of the variation in body weight can be explained by the variation in hind foot length (R2 =0.3).\nE. Citations:\nKielland, K., F.S. Chapin, R.W. Ruess, and Bonanza Creek LTER. 2017. Snowshoe hare physical data in Bonanza Creek Experimental Forest: 1999-Present ver 22. Environmental Data Initiative. URL Link\n\n\n\n",
    "preview": "posts/2021-02-20-snowshoe-hares-in-bonanza-creek/snowshoe-hares-in-bonanza-creek_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-02-20T16:49:37-08:00",
    "input_file": "snowshoe-hares-in-bonanza-creek.utf8.md"
  },
  {
    "path": "posts/2021-02-03-break-free-from-plastic/",
    "title": "Break Free From Plastic",
    "description": "1.26.2021 TidyTuesday - Choropleth Map Using `rnaturalearth`",
    "author": [
      {
        "name": "Kathleen Cotti",
        "url": {}
      }
    ],
    "date": "2021-02-03",
    "categories": [],
    "contents": "\nSummary:\nThis post explores how to analyze spatial data & build a choropleth map with the rnaturalearth package to participate in Tidy Tuesday 1.26.2021. This post shows how to load in tidyTuesday data, merge spatial data frames using left_join, and build a finalized choropleth map. I wanted to look at total plastic counts by country and display this on a spatial map. This is my first attempt at spacial data visualization and it was exciting to give spatial mapping a try for tidy tuesday!\nAt first, I had issues reading in a spatial data frame for the world map outline, but the rnaturalearth package has built in world maps. I made a world map showing the total plastic counts for 2020 and played around with the viridis package to update the color gradient of the map, and I learned how to change background color of a plot using plot.background in theme().\nReading in tidyTuesday data:\n\n\nhide\n\n# Read in the data:\nplastics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-01-26/plastics.csv')\n\n\n\nData Wrangling:\nFor this map I wanted to look at total plastic counts for 2020, so I filtered the data using various functions from the dplyr package:\n\n\nhide\n\n# Data Wrangling - Sum of total plastic counts by country:\nplastics_summary <- plastics %>% \n# Remove NA values:\n  drop_na(grand_total) %>% \n# Filter to only keep counts from 2020:\n  filter(year == 2020) %>% \n# Group by country:\n  group_by(country) %>% \n# Find total plastics per country: \n  summarize(total_plastics = sum(grand_total)) \n\n\n\nMaking a chloropleth map using the ‘rnaturalearth’ package:\n\n\nhide\n\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\") \n\nworld_p <- plastics_summary %>% \n  left_join(world, ., by = c(\"name\" = \"country\"))\n\nggplot() +\n  geom_sf(data = world_p,\n          aes(fill = total_plastics), color = NA) +\n  scale_fill_viridis(option = \"viridis\",\n                     begin = 0.25,\n                     end = 1,\n                     breaks = c(10000, 20000,30000,40000,50000,60000),\n                     name = \"Total Plastics\")   +\n  theme_void() +\n  theme(plot.background = element_rect(fill = \"#f5f5f2\", color = NA)) +\n  labs(title = \"Worldwide Total Plastic Counts in 2020\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-03-break-free-from-plastic/break-free-from-plastic_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-02-20T15:58:06-08:00",
    "input_file": {}
  }
]
